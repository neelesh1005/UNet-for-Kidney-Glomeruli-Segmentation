{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960"
      ],
      "metadata": {
        "id": "QN2V55j3Gyon"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tifffile\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Dropout, Input, Conv2DTranspose, Concatenate, Activation, Reshape, Lambda\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.data import Dataset\n",
        "import keras.backend as K\n",
        "tf.config.optimizer.set_jit(True)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "BjurgjBzGyoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X_input,output_channels,kernel_size,strides,padding):\n",
        "\n",
        "    X_input = Conv2D(output_channels, kernel_size = kernel_size, strides = strides, padding = padding, kernel_initializer = tf.keras.initializers.HeNormal())(X_input)\n",
        "\n",
        "    X_input = BatchNormalization()(X_input)\n",
        "\n",
        "    X_input = Activation('relu')(X_input)\n",
        "\n",
        "    return X_input"
      ],
      "metadata": {
        "trusted": true,
        "id": "nksk-QT6Gyop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_block(X_input,output_channels,kernel_size,strides):\n",
        "\n",
        "    X_input = conv_block(X_input,output_channels, kernel_size=kernel_size, strides=strides, padding = 'same')\n",
        "\n",
        "    X_concat = conv_block(X_input,output_channels, kernel_size=kernel_size, strides=strides, padding = 'same')\n",
        "\n",
        "    X_down = Conv2D(output_channels, kernel_size = (2,2), strides = 2, padding = 'valid', activation = 'relu')(X_concat)\n",
        "\n",
        "    return X_concat, X_down\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "kpy8PY7RGyop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def middle_block(X_input,output_channels,kernel_size,strides):\n",
        "\n",
        "    X_input = conv_block(X_input,output_channels, kernel_size=kernel_size, strides=strides, padding = 'same')\n",
        "\n",
        "    X_input = conv_block(X_input,output_channels, kernel_size=kernel_size, strides=strides, padding = 'same')\n",
        "\n",
        "    X_upward = Conv2DTranspose(output_channels, kernel_size = (3,3), strides = (2, 2), padding = 'same')(X_input)\n",
        "\n",
        "\n",
        "\n",
        "    return X_upward"
      ],
      "metadata": {
        "trusted": true,
        "id": "Kac_SiaMGyop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_block(X_concat,X_upward,output_channels,kernel_size,strides, last = False):\n",
        "\n",
        "    X_input = Concatenate()([X_concat,X_upward])\n",
        "\n",
        "    X_input = Dropout(0.1)(X_input)\n",
        "\n",
        "    X_input = conv_block(X_input,output_channels, kernel_size,strides,padding='same')\n",
        "\n",
        "    X_input = conv_block(X_input,output_channels,kernel_size,strides,padding='same')\n",
        "\n",
        "    if not last:\n",
        "\n",
        "        X_input = Conv2DTranspose(output_channels, kernel_size = (3,3), strides = (2, 2), padding = 'same')(X_input)\n",
        "\n",
        "    return X_input\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "na0bW_tJGyop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_loss(y_true, y_pred):\n",
        "\n",
        "    def dice_coef(y_true, y_pred, smooth=1):\n",
        "\n",
        "        intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "        return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
        "\n",
        "\n",
        "    return 1-dice_coef(y_true, y_pred)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "7rvOG4ElGyop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Unet():\n",
        "\n",
        "    ks = (3,3)\n",
        "\n",
        "    s = 1\n",
        "\n",
        "    X_input = Input(shape=(256,256,3))\n",
        "\n",
        "    X_rescale = Rescaling(scale = 1./255)(X_input)\n",
        "\n",
        "    X_concat1, X_down = encoder_block(X_rescale,output_channels = 32, kernel_size = ks, strides = s)\n",
        "\n",
        "    X_concat2, X_down = encoder_block(X_down, output_channels = 64, kernel_size = ks, strides = s)\n",
        "\n",
        "    X_concat3, X_down = encoder_block(X_down, output_channels = 128, kernel_size = ks, strides = s)\n",
        "\n",
        "    X_upward1 = middle_block(X_down, output_channels = 128, kernel_size = ks, strides = s)\n",
        "\n",
        "    X_upward2 = decoder_block(X_concat3, X_upward1, output_channels = 64, kernel_size = ks, strides = s)\n",
        "\n",
        "    X_upward3 = decoder_block(X_concat2, X_upward2, output_channels = 32, kernel_size = ks, strides = s)\n",
        "\n",
        "    X_last = decoder_block(X_concat1, X_upward3, output_channels = 32, kernel_size = ks, strides = s, last = True)\n",
        "\n",
        "    X_last = Conv2D(1, kernel_size = ks, strides = s, padding = 'same', activation = 'sigmoid')(X_last)\n",
        "\n",
        "    X_output = Reshape((256,256))(X_last)\n",
        "\n",
        "    model = Model(inputs = X_input, outputs= X_output)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "iTB4WS0DGyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Unet()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Pfn0niuRGyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = dice_loss, optimizer = Adam(learning_rate=0.0003), metrics = ['binary_accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "IpkKf3JqGyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "zBLa94VtGyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STDEV_THRESHOLD = 10\n",
        "overlap = 36"
      ],
      "metadata": {
        "trusted": true,
        "id": "H3Q_CGkhGyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boxes(file):\n",
        "\n",
        "    image = tifffile.imread(file)\n",
        "    image = np.squeeze(image)\n",
        "    if image.shape[0] == 3: #channels_first\n",
        "        image = np.transpose(image, (1, 2, 0))\n",
        "    assert image.shape[2] != 4\n",
        "    len_image, wid_image, _ = image.shape\n",
        "    list_range_len_image = list(range(0, len_image, 256-overlap))\n",
        "    random.shuffle(list_range_len_image)\n",
        "    list_range_wid_image = list(range(0, wid_image, 256-overlap))\n",
        "    for i in list_range_len_image:\n",
        "        random.shuffle(list_range_wid_image)\n",
        "        for j in list_range_wid_image:\n",
        "            output_array = np.array(image[i:i+256,j:j+256])\n",
        "            if output_array.shape == (256, 256, 3):\n",
        "                yield ((i, j), output_array)"
      ],
      "metadata": {
        "trusted": true,
        "id": "yuaIhDjpGyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIR = \"../input/hubmap-kidney-segmentation/train\"\n",
        "LABEL_DIR = \"../input/hubmaplabeling\"\n",
        "file_ids = [x.replace(\"-label.npy\", \"\") for x in os.listdir(\"../input/hubmaplabeling\")]\n",
        "\n",
        "def iterate_through_training_images():\n",
        "    random.shuffle(file_ids)\n",
        "    for file_id in file_ids:\n",
        "        label_arr = np.load(f\"../input/hubmaplabeling/{file_id}-label.npy\", mmap_mode=\"r\")\n",
        "        for (x, y), input_tile in boxes(f\"{INPUT_DIR}/{file_id}.tiff\"):\n",
        "            if np.std(input_tile.ravel()) >= STDEV_THRESHOLD:\n",
        "                input_tile = tf.convert_to_tensor(input_tile, tf.float32)\n",
        "                label_tile = tf.convert_to_tensor(label_arr[x:x+256, y:y+256], tf.float32)\n",
        "                yield input_tile, label_tile\n",
        "        del label_arr"
      ],
      "metadata": {
        "trusted": true,
        "id": "pWx5gp6cGyoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "trusted": true,
        "id": "AsLCN457Gyor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_generator(iterate_through_training_images,\n",
        "                                            output_signature=(\n",
        "                                                 tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32),\n",
        "                                                 tf.TensorSpec(shape=(256, 256), dtype=tf.float32)))\n",
        "dataset = dataset.shuffle(100)\n",
        "\n",
        "validation_dataset = dataset.take(500).batch(1)\n",
        "\n",
        "training_dataset = dataset.skip(500).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "trusted": true,
        "id": "0mHudwqHGyor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_dataset, epochs = 7, validation_data = validation_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fX8G4l7kGyor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(validation_dataset)\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "oOJjKeX1Gyor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHnGNyGxGyor"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}